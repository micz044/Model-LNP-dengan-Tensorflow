# -*- coding: utf-8 -*-
"""Proyek_Pertama_Membuat_Model_NLP_dengan_TensorFlow.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1atrzqnWuPCI24prBEe6PRfStZnB4f2HM

# **Proyek pertama : Membuat model NLP dengan TensorFlow**

## Notebook By : Michael Vincent Efren Malamo

1. Persiapan Direktori Dan Dataset
"""

import tensorflow as tf
import pandas as pd
df = pd.read_csv('/content/drive/MyDrive/Dataset_Collab/job_postings.csv')

df.info()

"""2. Seleksi kolom yang akan digunakan"""

df = df[['title','description','formatted_work_type']]
df

category = pd.get_dummies(df.formatted_work_type)
new_df = pd.concat([df, category], axis=1)
new_df = new_df.drop(columns=['formatted_work_type'])
new_df.head()

job = new_df['title'].values
label = new_df[['Contract','Full-time','Internship','Other','Part-time','Temporary','Volunteer']].values

"""3. Preprocessing Data"""

from sklearn.model_selection import train_test_split

job_latih, job_test, label_latih, label_test = train_test_split(job, label, test_size=0.2)

"""Penggunaan Tokenizer dan padding"""

from tensorflow.keras.preprocessing.text import Tokenizer #type:ignore
from tensorflow.keras.preprocessing.sequence import pad_sequences  #type:ignore

tokenizer = Tokenizer (num_words=5000, oov_token='x')
tokenizer.fit_on_texts(job_latih)
tokenizer.fit_on_texts(job_test)

sequens_latih = tokenizer.texts_to_sequences(job_latih)
sequens_test = tokenizer.texts_to_sequences(job_test)

padded_latih = pad_sequences(sequens_latih)
padded_test = pad_sequences(sequens_test)

"""Penggunaan callbacks untuk mengatur threshold"""

class myCallbacks(tf.keras.callbacks.Callback):
  def on_epoch_end(self, epoch, logs={}):
    if(logs.get('accuracy') > 0.91):
      print('\nSelamat,akurasi melebihi 90 %')
      self.model.stop_training = True


callbacks = myCallbacks()

model = tf.keras.Sequential([
    tf.keras.layers.Embedding(input_dim = 5000, output_dim=16),
    tf.keras.layers.LSTM(64),
    tf.keras.layers.Dropout(0.6),
    tf.keras.layers.Dense(200, activation='relu'),
    tf.keras.layers.Dense(500, activation='relu'),
    tf.keras.layers.Dense(7, activation='softmax'),
])

model.compile(optimizer='Adam', loss='categorical_crossentropy',metrics=['accuracy'])

"""Melatih Model NLP"""

num_epoch = 30

history = model.fit(
    padded_latih,
    label_latih,
    epochs = num_epoch,
    validation_data=(padded_test,label_test),
    callbacks=[callbacks],
    verbose=1
)

"""Visualisasi plot akurasi Data Training Dan Data Test"""

# Commented out IPython magic to ensure Python compatibility.
# %matplotlib inline

import matplotlib.image as mpimg
import matplotlib.pyplot as plt

acc = history.history ['accuracy']
val_acc = history.history['val_accuracy']
loss = history.history['loss']
val_loss = history.history['val_loss']

epochs = range(len(acc))

plt.plot(epochs, acc, 'r', label = 'Training Accuracy')
plt.plot(epochs, val_acc, 'b', label = 'Validation Accuracy')
plt.title('Training and Validation Accuracy')
plt.legend(loc= 'best')
plt.show()

plt.plot(epochs, loss, 'r', label = 'Training loss')
plt.plot(epochs, val_acc, 'b', label = 'Validation Loss')
plt.title('Training and Validation loss')
plt.legend(loc= 'best')
plt.show()